# ----- Step 0: Configuration / Define Helper Functions----- #
library("purrr")
library("dplyr")
library("duckdb")
library("stringr")
library("tibble")
library("lme4")

# Function for getting group-level means
get_weighted_count <- function(variable, value, year) {
  # Coerce specific label strings to their underlying codes
  if (value == "male" && variable == "sex") {
    value <- 1
    variable <- "SEX"
  } else if (value == "female" && variable == "sex") {
      value <- 2
      variable <- "SEX"
  } else if (value == "homeowner" && variable == "tenure") {
    value <- 1
    variable <- "OWNERSHP"
  } else if (value == "renter" && variable == "tenure") {
    value <- 2
    variable <- "OWNERSHP"
  } else if (variable == "cpuma") {
    value <- as.integer(value)
    variable <- "CPUMA0010"
  }
  
  # Default case
  ipums_db |>
    filter(YEAR == !!year, GQ %in% c(0, 1, 2)) |>
    filter(!!sym(variable) == !!value) |>
    summarise(weighted_count = sum(PERWT), na.rm = TRUE) |>
    collect() |>
    pull(weighted_count)
}


# Function for tidying regression results
tidy_regression <- function(model, varnames = varnames_dict) {
  coefs <- as_tibble(model$coeftable, rownames = "coef") |>
    select(coef, Estimate) |>
    mutate(
      variable = map_chr(coef, ~ varnames[str_detect(.x, fixed(varnames))][1]),
      value = if_else(!is.na(variable), str_remove(coef, fixed(variable)), coef)
    )
  
  fes <- fixef(model)[["cpuma"]] |>
    enframe(name = "value", value = "Estimate") |>
    mutate(variable = "cpuma", coef = paste0(variable, value))
  
  bind_rows(coefs, fes)
}

# Varnames fed into tidy_regression() function, above
varnames_dict <- c(
  "RACE_ETH_bucket",
  "AGE_bucket",
  "EDUC_bucket",
  "INCTOT_cpiu_2010_bucket",
  "us_born",
  "sex",
  "tenure"
)

# ----- STEP 1: Clean the regression results ---- #
# Load regression results generated by kob/scripts/linear-regressions.R
load("kob/throughput/regression_models.RData")

# Clean them
reg01_2000_tbl <- tidy_regression(reg01_2000) |> 
  rename(estimate_2000 = Estimate)

reg01_2019_tbl <- tidy_regression(reg01_2019) |> 
  rename(estimate_2019 = Estimate)

# Combine them
coef_df <- left_join(
  reg01_2000_tbl,
  reg01_2019_tbl,
  by = c("coef", "variable", "value")
)
  
# ----- Step 2: Append group-level means ----- #
# First, load in the database
con <- dbConnect(duckdb::duckdb(), "data/db/ipums.duckdb")
ipums_db <- tbl(con, "ipums_processed")
  
# High level population means
pop_2000 <- ipums_db |> filter(YEAR == 2000, GQ %in% c(0, 1, 2)) |> 
  summarize(weighted_count = sum(PERWT), na.rm = TRUE) |>
  collect() |>
  pull(weighted_count)

pop_2019 <- ipums_db |> filter(YEAR == 2019, GQ %in% c(0, 1, 2)) |> 
  summarize(weighted_count = sum(PERWT), na.rm = TRUE) |>
  collect() |>
  pull(weighted_count)

# Now append group-level means using the helper function get_weighted_count (defined
# above)
coef <- coef_df |>
  mutate(
    weighted_count_2000 = pmap_dbl(
      list(variable = variable, value = value),
      ~ get_weighted_count(..1, ..2, 2000)
    ),
    weighted_count_2019 = pmap_dbl(
      list(variable = variable, value = value),
      ~ get_weighted_count(..1, ..2, 2019)
    ),
    prop_2019 = weighted_count_2019 / pop_2019,
    prop_2000 = weighted_count_2000 / pop_2000
  ) 

save(coef, file = "kob/throughput/ready-for-kob.RData")

# ----- STEP 2: Do the KOB ----- #
load("kob/throughput/ready-for-kob.RData")


coef <- coef |>
  mutate(
    e_component = estimate_2019*(prop_2019 - prop_2000),
    c_component = (estimate_2019 - estimate_2000)*prop_2000
  )

u <- intercept_2019 - intercept_2000
e <- sum(coef$e_component, na.rm = TRUE)
c <- sum(coef$c_component, na.rm = TRUE)
u
e
c

sum(u,e,c)

lm(data = ipums_db |> filter(YEAR == 2000, GQ %in% c(0, 1, 2)), 
   formula = NUMPREC ~ 1,
   weights = PERWT)$coefficients -> mean_hhsize_2000
lm(data = ipums_db |> filter(YEAR == 2019, GQ %in% c(0, 1, 2)), 
   formula = NUMPREC ~ 1,
   weights = PERWT)$coefficients -> mean_hhsize_2019

mean_hhsize_2019 - mean_hhsize_2000
